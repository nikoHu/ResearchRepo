{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        datas = json.load(file)\n",
    "\n",
    "    dataset = []\n",
    "    for data in datas:\n",
    "        user_info = []\n",
    "        for key, value in data[\"user_info\"].items():\n",
    "            if value:\n",
    "                user_info.append(f\"{key}_{value}\")\n",
    "        \n",
    "        parameter = []\n",
    "        for key, value in data[\"parameter\"].items():\n",
    "            if value:\n",
    "                parameter.append(f\"{key}_{value}\")\n",
    "        dataset.append({\"user_info\": user_info, \"parameter\": parameter})\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1217, 4691)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../../train_data/type_1/data.json\"\n",
    "dataset = process_data(data_path)\n",
    "\n",
    "# special symbols\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "# make vocab\n",
    "user_info_vocab = list(special_symbols)\n",
    "parameter_vocab = list(special_symbols)\n",
    "\n",
    "for data in dataset:\n",
    "    user_info_vocab.extend(data[\"user_info\"])\n",
    "    parameter_vocab.extend(data[\"parameter\"])\n",
    "\n",
    "user_info_vocab = sorted(list(set(user_info_vocab)))\n",
    "parameter_vocab = sorted(list(set(parameter_vocab)))\n",
    "\n",
    "len(user_info_vocab), len(parameter_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: <bos> —— Index: 0\n",
      "Word: <eos> —— Index: 1\n",
      "Word: <pad> —— Index: 2\n",
      "Word: <unk> —— Index: 3\n",
      "Word: age_1 —— Index: 4\n",
      "Word: age_10 —— Index: 5\n",
      "Word: age_104 —— Index: 6\n",
      "Word: age_1048 —— Index: 7\n",
      "Word: age_11 —— Index: 8\n",
      "Word: age_12 —— Index: 9\n",
      "Word: age_13 —— Index: 10\n",
      "Word: age_14 —— Index: 11\n",
      "Word: age_15 —— Index: 12\n",
      "Word: age_16 —— Index: 13\n",
      "Word: age_17 —— Index: 14\n",
      "Word: age_18 —— Index: 15\n",
      "Word: age_19 —— Index: 16\n",
      "Word: age_2 —— Index: 17\n",
      "Word: age_20 —— Index: 18\n",
      "Word: age_21 —— Index: 19\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(user_info_vocab):\n",
    "    if index < 20:\n",
    "        print(f\"Word: {word} —— Index: {index}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../../train_data/type_1/train.json\"\n",
    "valid_path = \"../../train_data/type_1/valid.json\"\n",
    "\n",
    "train_dataset = process_data(train_path)\n",
    "valid_dataset = process_data(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "token_train_dataset = []\n",
    "for data in train_dataset:\n",
    "    user_info = [user_info_vocab.index(word) for word in data[\"user_info\"]]\n",
    "    parameter = [parameter_vocab.index(word) for word in data[\"parameter\"]]\n",
    "    token_train_dataset.append({\"user_info\": user_info, \"parameter\": parameter})\n",
    "\n",
    "\n",
    "token_valid_dataset = []\n",
    "for data in valid_dataset:\n",
    "    user_info = [user_info_vocab.index(word) for word in data[\"user_info\"]]\n",
    "    parameter = [parameter_vocab.index(word) for word in data[\"parameter\"]]\n",
    "    token_valid_dataset.append({\"user_info\": user_info, \"parameter\": parameter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_info': [33, 1099, 1006, 889, 933, 956, 1029, 448, 333, 376, 404, 474], 'parameter': [6, 73, 119, 165, 211, 257, 303, 349, 398, 443, 490, 540, 588, 633, 676, 722, 768, 828, 875, 923, 971, 1019, 1067, 1115, 1160, 1199, 1236, 1284, 1328, 1376, 1422, 1470, 1518, 1538, 1560, 1579, 1598, 1617, 1636, 1655, 1674, 1694, 1715, 1736, 1757, 1778, 1799, 1819, 1839, 1847, 1879, 1911, 1955, 2002, 2049, 2096, 2143, 2190, 2237, 2285, 2325, 2371, 2420, 2467, 2514, 2572, 2616, 2663, 2710, 2757, 2804, 2851, 2892, 2935, 2973, 3012, 3067, 3103, 3154, 3200, 3246, 3258, 3282, 3318, 3362, 3409, 3456, 3503, 3550, 3597, 3644, 3692, 3732, 3778, 3827, 3874, 3921, 3979, 4023, 4070, 4117, 4164, 4211, 4258, 4299, 4342, 4380, 4419, 4474, 4510, 4561, 4607, 4653, 4667, 4673, 4676, 4677, 4683, 4688]}\n"
     ]
    }
   ],
   "source": [
    "for data in token_train_dataset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HearingAidDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user_info = self.dataset[idx][\"user_info\"]\n",
    "        user_info.insert(0, 0)\n",
    "        user_info.append(1)\n",
    "        \n",
    "        param = self.dataset[idx][\"parameter\"]\n",
    "        param.insert(0, 0)\n",
    "        param.append(1)\n",
    "        \n",
    "        user_info_tensor = torch.tensor(user_info)\n",
    "        param_tensor = torch.tensor(param)\n",
    "\n",
    "        return user_info_tensor, param_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=300, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0) # Shape (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x: (batch_size, x_len, d_model)\n",
    "            requires_grad_(False) is used to prevent the model from updating the positional encoding\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerMultiOutputRegressor(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_heads, n_layers, dropout=0.1, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.src_tok_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.trasformer = nn.Transformer(\n",
    "            d_model=d_model, \n",
    "            nhead=n_heads, \n",
    "            num_encoder_layers=n_layers, \n",
    "            num_decoder_layers=n_layers,\n",
    "            dropout=dropout, \n",
    "            batch_first=batch_first\n",
    "        )\n",
    "        self.positional_encoding = PositionalEncoding(d_model=d_model, dropout=dropout)\n",
    "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_key_padding_mask = (src == 2)\n",
    "        tgt_key_padding_mask = (tgt == 2)\n",
    "        src_mask = self.trasformer.generate_square_subsequent_mask(src.size(1)).bool().to(DEVICE)\n",
    "        tgt_mask = self.trasformer.generate_square_subsequent_mask(tgt.size(1)).bool().to(DEVICE)\n",
    "\n",
    "        src = self.src_tok_emb(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        tgt = self.tgt_tok_emb(tgt)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "\n",
    "        outs = self.trasformer(\n",
    "            src, tgt,\n",
    "            src_mask=src_mask, tgt_mask=tgt_mask,\n",
    "            src_key_padding_mask=src_key_padding_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            tgt_is_causal=True, memory_is_causal=False\n",
    "        )\n",
    "        return self.generator(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "src_vocab_size = len(user_info_vocab)\n",
    "tgt_vocab_size = len(parameter_vocab)\n",
    "d_model = 128\n",
    "n_heads = 8\n",
    "n_layers = 6\n",
    "dropout = 0.1\n",
    "batch_first = True\n",
    "\n",
    "model = TransformerMultiOutputRegressor(src_vocab_size, tgt_vocab_size, d_model, n_heads, n_layers, dropout, batch_first).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "batch_size = 64\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    user_info, param = zip(*batch)\n",
    "    user_info = nn.utils.rnn.pad_sequence(user_info, batch_first=True, padding_value=2)\n",
    "    param = nn.utils.rnn.pad_sequence(param, batch_first=True, padding_value=2)\n",
    "\n",
    "    return user_info, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = HearingAidDataset(token_train_dataset)\n",
    "valid_dataset = HearingAidDataset(token_valid_dataset)\n",
    "\n",
    "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_info shape: torch.Size([64, 35])\n",
      "param shape: torch.Size([64, 121])\n",
      "logits size: 4691\n",
      "torch.Size([64, 120, 4691])\n",
      "torch.Size([7680, 4691])\n",
      "torch.Size([64, 120])\n",
      "torch.Size([7680])\n"
     ]
    }
   ],
   "source": [
    "for user_info, param in training_loader:\n",
    "    user_info = user_info.to(DEVICE)\n",
    "    param = param.to(DEVICE)\n",
    "    print(f\"user_info shape: {user_info.shape}\")\n",
    "    print(f\"param shape: {param.shape}\")\n",
    "    param_input = param[:, :-1]\n",
    "    param_target = param[:, 1:]\n",
    "\n",
    "    logits = model(user_info, param_input)\n",
    "    print(f\"logits size: {logits.size(-1)}\")\n",
    "    print(logits.shape)\n",
    "    print(logits.reshape(-1, logits.size(-1)).shape)\n",
    "    print(param_target.shape)\n",
    "    print(param_target.reshape(-1).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train_epoch(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_info, param in training_loader:\n",
    "        user_info = user_info.to(DEVICE)\n",
    "        param = param.to(DEVICE)\n",
    "        \n",
    "        param_input = param[:, :-1]\n",
    "        param_target = param[:, 1:]\n",
    "\n",
    "        logits = model(user_info, param_input)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(logits.reshape(-1, logits.size(-1)), param_target.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(training_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for user_info, param in valid_loader:\n",
    "            user_info = user_info.to(DEVICE)\n",
    "            param = param.to(DEVICE)\n",
    "            param_input = param[:, :-1]\n",
    "            param_target = param[:, 1:]\n",
    "\n",
    "            logits = model(user_info, param_input)\n",
    "            loss = loss_fn(logits.reshape(-1, logits.size(-1)), param_target.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉熵损失\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=2)\n",
    "# 优化器：Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from timeit import default_timer as timer\n",
    "\n",
    "# training_losses = []\n",
    "# valid_losses = []\n",
    "# for epoch in range(num_epochs):\n",
    "#     start_time = timer()\n",
    "#     train_loss = train_epoch(model, loss_fn, optimizer)\n",
    "#     training_losses.append(train_loss)\n",
    "#     end_time = timer()\n",
    "#     valid_loss = evaluate(model, loss_fn)\n",
    "#     valid_losses.append(valid_loss)\n",
    "#     print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Valid loss: {valid_loss:.3f}, Time: {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the loss curve\n",
    "# plt.plot(training_losses, label='Training Loss')\n",
    "# plt.plot(valid_losses, label='Validation Loss')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# torch.save(model.state_dict(), '../models/transformer_type_1_80.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerMultiOutputRegressor:\n\tsize mismatch for src_tok_emb.weight: copying a param with shape torch.Size([1216, 128]) from checkpoint, the shape in current model is torch.Size([1217, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 加载模型\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/transformer_type_1_80.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/share/pdm/venvs/match-data-DLs9GDz--match-data/lib/python3.10/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TransformerMultiOutputRegressor:\n\tsize mismatch for src_tok_emb.weight: copying a param with shape torch.Size([1216, 128]) from checkpoint, the shape in current model is torch.Size([1217, 128])."
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model.load_state_dict(torch.load('../models/transformer_type_1_80.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data):\n",
    "    # Randomly select a sample from the test set\n",
    "    user_info = test_data[\"user_info\"]\n",
    "    param = test_data[\"parameter\"]\n",
    "\n",
    "    user_info_token = [user_info_vocab.index(word) for word in user_info]\n",
    "    user_info_token.insert(0, 0)\n",
    "    user_info_token.append(1)\n",
    "\n",
    "    param_token = [parameter_vocab.index(word) for word in param]\n",
    "    param_token.insert(0, 0)\n",
    "    param_token.append(1)\n",
    "\n",
    "    user_info_tensor = torch.tensor(user_info_token).unsqueeze(0).to(DEVICE)\n",
    "    param_tensor = torch.tensor(param_token).unsqueeze(0).to(DEVICE)\n",
    "    param_input = param_tensor[:, :-1]\n",
    "    param_target = param_tensor[:, 1:]\n",
    "\n",
    "    logits = model(user_info_tensor, param_input)\n",
    "    # print(f\"logits shape: {logits.shape}\")\n",
    "\n",
    "    # Softmax\n",
    "    logits_probs = nn.functional.softmax(logits, dim=-1)\n",
    "    # print(f\"logits_probs shape: {logits_probs.shape}\")\n",
    "\n",
    "    # Argmax\n",
    "    logits_argmax = torch.argmax(logits, dim=-1)\n",
    "    # print(f\"logits_argmax shape: {logits_argmax.shape}\")\n",
    "\n",
    "    # Argmax to Index\n",
    "    logits_argmax = logits_argmax.squeeze(0).cpu().numpy().tolist()\n",
    "\n",
    "    # Logits_argmax to Word\n",
    "    logits_words = [parameter_vocab[i] for i in logits_argmax]\n",
    "\n",
    "    real = [item.split('_')[-1] for item in param]\n",
    "    pred = [item.split('_')[-1] for item in logits_words[:-1]]\n",
    "\n",
    "    return real, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.75%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>真实值</th>\n",
       "      <th>预测值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    真实值 预测值\n",
       "0     8   6\n",
       "1    28  38\n",
       "2    39  32\n",
       "3    39  39\n",
       "4    39  39\n",
       "5    39  39\n",
       "6    39  39\n",
       "7    39  39\n",
       "8    39  32\n",
       "9    34  42\n",
       "10   30  34\n",
       "11   22  27\n",
       "12   40  37\n",
       "13   35  28\n",
       "14   39  39\n",
       "15   39  39\n",
       "16   39  39\n",
       "17   41  41\n",
       "18   52  52\n",
       "19   52  52\n",
       "20   52  52\n",
       "21   52  52\n",
       "22   52  52\n",
       "23   52  52\n",
       "24   52  49\n",
       "25   47  46\n",
       "26   43  43\n",
       "27   38  38\n",
       "28   53  52\n",
       "29   48  47\n",
       "30   52  52\n",
       "31   52  52\n",
       "32   52  52\n",
       "33   34  34\n",
       "34   34  34\n",
       "35   34  34\n",
       "36   34  34\n",
       "37   34  34\n",
       "38   34  34\n",
       "39   34  34\n",
       "40   34  34\n",
       "41   34  34\n",
       "42   34  34\n",
       "43   34  34\n",
       "44   34  34\n",
       "45   34  34\n",
       "46   34  34\n",
       "47   34  34\n",
       "48   34  34\n",
       "49   15  15\n",
       "50    3   7\n",
       "51   28  28\n",
       "52   39  40\n",
       "53   39  39\n",
       "54   39  39\n",
       "55   39  39\n",
       "56   39  39\n",
       "57   39  39\n",
       "58   39  39\n",
       "59   34  34\n",
       "60   22  22\n",
       "61   35  35\n",
       "62   39  39\n",
       "63   39  39\n",
       "64   39  39\n",
       "65   41  41\n",
       "66   52  44\n",
       "67   52  52\n",
       "68   52  52\n",
       "69   52  52\n",
       "70   52  52\n",
       "71   52  52\n",
       "72   52  52\n",
       "73   47  47\n",
       "74   43  43\n",
       "75   38  35\n",
       "76   53  50\n",
       "77   48  48\n",
       "78   52  52\n",
       "79   52  52\n",
       "80   52  52\n",
       "81   15  15\n",
       "82   28  28\n",
       "83   39  39\n",
       "84   39  39\n",
       "85   39  39\n",
       "86   39  39\n",
       "87   39  39\n",
       "88   39  39\n",
       "89   39  39\n",
       "90   34  34\n",
       "91   22  22\n",
       "92   35  35\n",
       "93   39  39\n",
       "94   39  39\n",
       "95   39  39\n",
       "96   41  41\n",
       "97   52  52\n",
       "98   52  52\n",
       "99   52  52\n",
       "100  52  52\n",
       "101  52  52\n",
       "102  52  52\n",
       "103  52  52\n",
       "104  47  47\n",
       "105  43  43\n",
       "106  38  38\n",
       "107  53  53\n",
       "108  48  48\n",
       "109  52  52\n",
       "110  52  52\n",
       "111  52  52\n",
       "112  40  40\n",
       "113  70  70\n",
       "114  10  10\n",
       "115  12  12\n",
       "116   6   6\n",
       "117   3   3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set display columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# randomly select a sample from the test set\n",
    "test_path = \"../../train_data/type_1/test.json\"\n",
    "test_dataset = process_data(test_path)\n",
    "\n",
    "sample = random.choice(test_dataset)\n",
    "real, pred = predict(sample)\n",
    "\n",
    "# calculate the accuracy\n",
    "correct = 0\n",
    "for a, b in zip(real, pred):\n",
    "    if a == b:\n",
    "        correct += 1\n",
    "print(f\"Accuracy: {correct / len(real) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    '真实值': real,\n",
    "    '预测值': pred\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 81.24%\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "for item in test_dataset:\n",
    "    reals, preds = predict(item)\n",
    "    correct = 0\n",
    "    for real, pred in zip(reals, preds):\n",
    "        if real == pred:\n",
    "            correct += 1\n",
    "    accuracy.append(correct / len(reals))\n",
    "\n",
    "print(f\"Average Accuracy: {sum(accuracy) / len(accuracy) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
