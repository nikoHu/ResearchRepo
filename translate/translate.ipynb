{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集：Tatoeba项目的双语句子对 https://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import math\n",
    "import spacy\n",
    "import jieba\n",
    "import random\n",
    "from opencc import OpenCC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# 设置随机种子以确保结果可重复\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 定义特殊标记\n",
    "SPECIAL_TOKENS = ['<pad>', '<bos>', '<eos>', '<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 检查是否有可用的GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前5条数据:\n",
      "('Hi.', '嗨。')\n",
      "('Hi.', '你好。')\n",
      "('Run.', '你用跑的。')\n",
      "('Stop!', '住手！')\n",
      "('Wait!', '等等！')\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理函数\n",
    "cc = OpenCC('t2s')  # 繁体转简体\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "            en, zh = parts[0], parts[1]\n",
    "            zh = cc.convert(zh)  # 繁体转简体\n",
    "            data.append((en, zh))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 读取并预处理数据\n",
    "data = preprocess_data('cmn.txt')\n",
    "\n",
    "# 输出前5条数据\n",
    "print(\"前5条数据:\")\n",
    "for item in data[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 23927\n",
      "验证集大小: 2991\n",
      "测试集大小: 2991\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集函数\n",
    "def split_data(data, test_ratio=0.1, val_ratio=0.1):\n",
    "    # 先随机打乱整个数据集\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # 计算分割点\n",
    "    test_split = int(len(data) * (1 - test_ratio))\n",
    "    val_split = int(len(data) * (1 - test_ratio - val_ratio))\n",
    "    \n",
    "    # 分割数据集\n",
    "    train_data = data[:val_split]\n",
    "    val_data = data[val_split:test_split]\n",
    "    test_data = data[test_split:]\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# 分割数据集\n",
    "train_data, val_data, test_data = split_data(data)\n",
    "\n",
    "print(f\"训练集大小: {len(train_data)}\")\n",
    "print(f\"验证集大小: {len(val_data)}\")\n",
    "print(f\"测试集大小: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.309 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文词典大小: 6521\n",
      "中文词典大小: 11340\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(sentences, tokenizer):\n",
    "    vocab = {}\n",
    "    for token in SPECIAL_TOKENS:\n",
    "        vocab[token] = len(vocab)\n",
    "    for sentence in sentences:\n",
    "        for word in tokenizer(sentence):\n",
    "            if word not in vocab:\n",
    "                vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "# 加载分词器\n",
    "jieba.initialize()\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "# 构建词典\n",
    "en_sentences = [pair[0] for pair in train_data]\n",
    "zh_sentences = [pair[1] for pair in train_data]\n",
    "\n",
    "en_vocab = build_vocab(en_sentences, lambda x: [token.text.lower() for token in spacy_en.tokenizer(x)])\n",
    "zh_vocab = build_vocab(zh_sentences, jieba.lcut)\n",
    "\n",
    "print(f\"英文词典大小: {len(en_vocab)}\")\n",
    "print(f\"中文词典大小: {len(zh_vocab)}\")\n",
    "\n",
    "# 反向词典，用于将索引转换回单词\n",
    "inv_en_vocab = {v: k for k, v in en_vocab.items()}\n",
    "inv_zh_vocab = {v: k for k, v in zh_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文词典:\n",
      "Index: 0, Word: <pad>\n",
      "Index: 1, Word: <bos>\n",
      "Index: 2, Word: <eos>\n",
      "Index: 3, Word: <unk>\n",
      "Index: 4, Word: 汤姆\n",
      "Index: 5, Word: 应当\n",
      "Index: 6, Word: 被\n",
      "Index: 7, Word: 责备\n",
      "Index: 8, Word: 。\n",
      "Index: 9, Word: 我\n",
      "Index: 10, Word: 将要\n",
      "Index: 11, Word: 在\n",
      "Index: 12, Word: 这里\n",
      "Index: 13, Word: 待\n",
      "Index: 14, Word: 几天\n",
      "\n",
      "**************************\n",
      "英文词典:\n",
      "Index: 0, Word: <pad>\n",
      "Index: 1, Word: <bos>\n",
      "Index: 2, Word: <eos>\n",
      "Index: 3, Word: <unk>\n",
      "Index: 4, Word: tom\n",
      "Index: 5, Word: deserves\n",
      "Index: 6, Word: to\n",
      "Index: 7, Word: be\n",
      "Index: 8, Word: blamed\n",
      "Index: 9, Word: .\n",
      "Index: 10, Word: i\n",
      "Index: 11, Word: am\n",
      "Index: 12, Word: going\n",
      "Index: 13, Word: stay\n",
      "Index: 14, Word: here\n"
     ]
    }
   ],
   "source": [
    "# 遍历中文词典\n",
    "print(\"中文词典:\")\n",
    "for i, (k, v) in enumerate(zh_vocab.items()):\n",
    "    if i >= 15:\n",
    "        break\n",
    "    print(f\"Index: {v}, Word: {k}\")\n",
    "\n",
    "print(\"\\n**************************\")\n",
    "\n",
    "# 遍历英文词典\n",
    "print(\"英文词典:\")\n",
    "for i, (k, v) in enumerate(en_vocab.items()):\n",
    "    if i >= 15:\n",
    "        break\n",
    "    print(f\"Index: {v}, Word: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, en_vocab, zh_vocab):\n",
    "        self.data = data\n",
    "        self.en_vocab = en_vocab\n",
    "        self.zh_vocab = zh_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en, zh = self.data[idx]\n",
    "        en_tokens = [self.en_vocab.get(token.text.lower(), self.en_vocab['<unk>']) \n",
    "                     for token in spacy_en.tokenizer(en)]\n",
    "        zh_tokens = [self.zh_vocab.get(token, self.zh_vocab['<unk>']) \n",
    "                     for token in jieba.lcut(zh)]\n",
    "        \n",
    "        en_tokens = [self.en_vocab['<bos>']] + en_tokens + [self.en_vocab['<eos>']]\n",
    "        zh_tokens = [self.zh_vocab['<bos>']] + zh_tokens + [self.zh_vocab['<eos>']]\n",
    "        \n",
    "        return torch.tensor(en_tokens), torch.tensor(zh_tokens)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    en_sequences, zh_sequences = zip(*batch)\n",
    "    \n",
    "    en_sequences = nn.utils.rnn.pad_sequence(en_sequences, padding_value=en_vocab['<pad>'], batch_first=True)\n",
    "    zh_sequences = nn.utils.rnn.pad_sequence(zh_sequences, padding_value=zh_vocab['<pad>'], batch_first=True)\n",
    "    \n",
    "    return en_sequences, zh_sequences\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_dataset = TranslationDataset(train_data, en_vocab, zh_vocab)\n",
    "test_dataset = TranslationDataset(test_data, en_vocab, zh_vocab)\n",
    "\n",
    "BATCH_SIZE = 64  # 根据8GB显存调整\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19])\n",
      "torch.Size([64, 14])\n",
      "src: tensor([   1,   34,   63,   21,  234, 5800,   68, 2918,   70,   34, 1769,  382,\n",
      "           9,    2,    0,    0,    0,    0,    0])\n",
      "tgt: tensor([   1,    9,   18,  113,  226, 3110,    9,   18, 7744,    8,    2,    0,\n",
      "           0,    0])\n"
     ]
    }
   ],
   "source": [
    "# 遍历dataloader\n",
    "for src, tgt in train_loader:\n",
    "    print(src.shape)\n",
    "    print(tgt.shape)\n",
    "    print(f\"src: {src[0]}\")\n",
    "    print(f\"tgt: {tgt[0]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "    \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        src_padding_mask = (src == en_vocab['<pad>']).to(device)\n",
    "        tgt_padding_mask = (tgt == zh_vocab['<pad>']).to(device)\n",
    "        \n",
    "        src = self.src_embedding(src) * math.sqrt(self.d_model)\n",
    "        tgt = self.tgt_embedding(tgt) * math.sqrt(self.d_model)\n",
    "        \n",
    "        src = self.positional_encoding(src)\n",
    "        tgt = self.positional_encoding(tgt)\n",
    "        \n",
    "        src_mask = None\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "        \n",
    "        # Convert padding masks to float and apply masking\n",
    "        if src_padding_mask is not None:\n",
    "            src_padding_mask = src_padding_mask.float().masked_fill(src_padding_mask, float('-inf'))\n",
    "        if tgt_padding_mask is not None:\n",
    "            tgt_padding_mask = tgt_padding_mask.float().masked_fill(tgt_padding_mask, float('-inf'))\n",
    "        \n",
    "        output = self.transformer(src, tgt, src_mask, tgt_mask, \n",
    "                                  src_key_padding_mask=src_padding_mask,\n",
    "                                  tgt_key_padding_mask=tgt_padding_mask)\n",
    "        \n",
    "        return self.fc_out(output)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (src_embedding): Embedding(6521, 256)\n",
       "  (tgt_embedding): Embedding(11340, 256)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=11340, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab_size = len(en_vocab)\n",
    "tgt_vocab_size = len(zh_vocab)\n",
    "d_model = 256\n",
    "nhead = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 512\n",
    "dropout = 0.1\n",
    "\n",
    "# 初始化模型\n",
    "model = TransformerModel(\n",
    "    src_vocab_size,\n",
    "    tgt_vocab_size,\n",
    "    d_model=d_model,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    num_decoder_layers=num_decoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            \n",
    "            output = model(src, tgt[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, output.size(-1)), tgt[:, 1:].contiguous().view(-1))\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTrain loss: 5.493, Val loss: 4.995, Epoch time = 5.718s\n",
      "Epoch: 2\tTrain loss: 4.485, Val loss: 4.657, Epoch time = 5.554s\n",
      "Epoch: 3\tTrain loss: 4.199, Val loss: 4.410, Epoch time = 5.440s\n",
      "Epoch: 4\tTrain loss: 3.984, Val loss: 4.320, Epoch time = 5.624s\n",
      "Epoch: 5\tTrain loss: 3.806, Val loss: 4.171, Epoch time = 6.000s\n",
      "Epoch: 6\tTrain loss: 3.656, Val loss: 4.126, Epoch time = 5.693s\n",
      "Epoch: 7\tTrain loss: 3.523, Val loss: 4.019, Epoch time = 5.685s\n",
      "Epoch: 8\tTrain loss: 3.406, Val loss: 3.946, Epoch time = 5.635s\n",
      "Epoch: 9\tTrain loss: 3.294, Val loss: 3.892, Epoch time = 5.722s\n",
      "Epoch: 10\tTrain loss: 3.193, Val loss: 3.819, Epoch time = 5.493s\n",
      "Epoch: 11\tTrain loss: 3.097, Val loss: 3.767, Epoch time = 5.732s\n",
      "Epoch: 12\tTrain loss: 3.006, Val loss: 3.723, Epoch time = 5.479s\n",
      "Epoch: 13\tTrain loss: 2.920, Val loss: 3.676, Epoch time = 5.573s\n",
      "Epoch: 14\tTrain loss: 2.838, Val loss: 3.600, Epoch time = 5.709s\n",
      "Epoch: 15\tTrain loss: 2.760, Val loss: 3.568, Epoch time = 5.644s\n",
      "Epoch: 16\tTrain loss: 2.683, Val loss: 3.538, Epoch time = 5.466s\n",
      "Epoch: 17\tTrain loss: 2.612, Val loss: 3.486, Epoch time = 5.782s\n",
      "Epoch: 18\tTrain loss: 2.538, Val loss: 3.471, Epoch time = 5.605s\n",
      "Epoch: 19\tTrain loss: 2.473, Val loss: 3.401, Epoch time = 5.487s\n",
      "Epoch: 20\tTrain loss: 2.407, Val loss: 3.403, Epoch time = 5.759s\n",
      "Epoch: 21\tTrain loss: 2.344, Val loss: 3.394, Epoch time = 5.578s\n",
      "Epoch: 22\tTrain loss: 2.283, Val loss: 3.307, Epoch time = 5.480s\n",
      "Epoch: 23\tTrain loss: 2.220, Val loss: 3.315, Epoch time = 5.472s\n",
      "Epoch: 24\tTrain loss: 2.163, Val loss: 3.271, Epoch time = 5.431s\n",
      "Epoch: 25\tTrain loss: 2.106, Val loss: 3.260, Epoch time = 5.751s\n",
      "Epoch: 26\tTrain loss: 2.051, Val loss: 3.242, Epoch time = 5.519s\n",
      "Epoch: 27\tTrain loss: 2.000, Val loss: 3.218, Epoch time = 5.624s\n",
      "Epoch: 28\tTrain loss: 1.944, Val loss: 3.184, Epoch time = 5.472s\n",
      "Epoch: 29\tTrain loss: 1.896, Val loss: 3.177, Epoch time = 5.699s\n",
      "Epoch: 30\tTrain loss: 1.847, Val loss: 3.154, Epoch time = 5.702s\n",
      "Epoch: 31\tTrain loss: 1.802, Val loss: 3.143, Epoch time = 5.721s\n",
      "Epoch: 32\tTrain loss: 1.751, Val loss: 3.139, Epoch time = 5.534s\n",
      "Epoch: 33\tTrain loss: 1.709, Val loss: 3.120, Epoch time = 5.423s\n",
      "Epoch: 34\tTrain loss: 1.664, Val loss: 3.090, Epoch time = 5.443s\n",
      "Epoch: 35\tTrain loss: 1.625, Val loss: 3.104, Epoch time = 5.556s\n",
      "Epoch: 36\tTrain loss: 1.580, Val loss: 3.096, Epoch time = 5.715s\n",
      "Epoch: 37\tTrain loss: 1.538, Val loss: 3.071, Epoch time = 5.685s\n",
      "Epoch: 38\tTrain loss: 1.499, Val loss: 3.058, Epoch time = 5.451s\n",
      "Epoch: 39\tTrain loss: 1.462, Val loss: 3.064, Epoch time = 5.405s\n",
      "Epoch: 40\tTrain loss: 1.426, Val loss: 3.066, Epoch time = 5.423s\n",
      "Epoch: 41\tTrain loss: 1.384, Val loss: 3.073, Epoch time = 5.502s\n",
      "Epoch: 42\tTrain loss: 1.352, Val loss: 3.056, Epoch time = 5.549s\n",
      "Epoch: 43\tTrain loss: 1.317, Val loss: 3.075, Epoch time = 5.520s\n",
      "Epoch: 44\tTrain loss: 1.288, Val loss: 3.062, Epoch time = 5.433s\n",
      "Epoch: 45\tTrain loss: 1.253, Val loss: 3.053, Epoch time = 5.631s\n",
      "Epoch: 46\tTrain loss: 1.222, Val loss: 3.037, Epoch time = 5.477s\n",
      "Epoch: 47\tTrain loss: 1.192, Val loss: 3.048, Epoch time = 5.419s\n",
      "Epoch: 48\tTrain loss: 1.159, Val loss: 3.026, Epoch time = 5.599s\n",
      "Epoch: 49\tTrain loss: 1.130, Val loss: 3.039, Epoch time = 5.573s\n",
      "Epoch: 50\tTrain loss: 1.099, Val loss: 3.064, Epoch time = 5.506s\n",
      "Epoch: 51\tTrain loss: 1.071, Val loss: 3.055, Epoch time = 5.662s\n",
      "Epoch: 52\tTrain loss: 1.043, Val loss: 3.052, Epoch time = 5.821s\n",
      "Epoch: 53\tTrain loss: 1.022, Val loss: 3.042, Epoch time = 5.741s\n",
      "验证损失在连续5个轮次内没有改善。提前停止训练。\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=zh_vocab['<pad>'])\n",
    "\n",
    "# 训练循环\n",
    "NUM_EPOCHS = 100\n",
    "patience = 5  # 连续5个epoch验证损失没有改善就停止\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    \n",
    "    train_loss = train(model, optimizer, criterion, train_loader, device)\n",
    "    \n",
    "    end_time = timer()\n",
    "    \n",
    "    val_loss = evaluate(model, criterion, test_loader, device)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\\tTrain loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s\")\n",
    "    \n",
    "    # 检查验证损失是否改善\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    # 如果连续多个epoch没有改善，则停止训练\n",
    "    if no_improvement >= patience:\n",
    "        print(f\"验证损失在连续{patience}个轮次内没有改善。提前停止训练。\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终模型及其他信息\n",
    "torch.save({\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_loss': train_loss,\n",
    "    'val_loss': val_loss,\n",
    "}, 'transformer_zh_en.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (src_embedding): Embedding(6521, 256)\n",
       "  (tgt_embedding): Embedding(11340, 256)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=256, out_features=11340, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载保存的模型\n",
    "checkpoint = torch.load('transformer_zh_en.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src_sentence, max_length=50):\n",
    "    model.eval()\n",
    "    src_tokens = [en_vocab.get(token.text.lower(), en_vocab['<unk>']) \n",
    "                  for token in spacy_en.tokenizer(src_sentence)]\n",
    "    src_tokens = [en_vocab['<bos>']] + src_tokens + [en_vocab['<eos>']]\n",
    "    src_tensor = torch.LongTensor(src_tokens).unsqueeze(0).to(device)\n",
    "    \n",
    "    tgt_tokens = [zh_vocab['<bos>']]\n",
    "    for i in range(max_length):\n",
    "        tgt_tensor = torch.LongTensor(tgt_tokens).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, tgt_tensor)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:, -1].item()\n",
    "        tgt_tokens.append(pred_token)\n",
    "        \n",
    "        if pred_token == zh_vocab['<eos>']:\n",
    "            break\n",
    "    \n",
    "    return ' '.join([inv_zh_vocab[token] for token in tgt_tokens[1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's next to impossible to finish it in a day.\", '在一天之内完成它几乎是不可能的。'),\n",
       " (\"I don't eat oranges.\", '我不吃橙子。'),\n",
       " ('They have been married two years.', '他们已经结婚两年了。'),\n",
       " ('She assumed an air of indifference.', '她假装不在意。'),\n",
       " ('Tom is our oldest son.', '汤姆是我们最大的儿子。')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datas = random.sample(val_data, 5)\n",
    "test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英文: It's next to impossible to finish it in a day.\n",
      "中文翻译: 下 一次 有 可能 完成 它 。\n",
      "\n",
      "英文: I don't eat oranges.\n",
      "中文翻译: 我 不吃 吃 完 了 。\n",
      "\n",
      "英文: They have been married two years.\n",
      "中文翻译: 他们 已经 结婚 了 。\n",
      "\n",
      "英文: She assumed an air of indifference.\n",
      "中文翻译: 她 怕 了 一个 饥饿 的 我怕 。\n",
      "\n",
      "英文: Tom is our oldest son.\n",
      "中文翻译: 汤姆 是 我们 的 儿子 。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试翻译\n",
    "test_sentences = [pair[0] for pair in test_datas]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translation = translate(model, sentence)\n",
    "    print(f\"英文: {sentence}\")\n",
    "    print(f\"中文翻译: {translation}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
